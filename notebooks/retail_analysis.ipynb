{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ec28eb98288c58",
   "metadata": {},
   "source": [
    "# StrategicGrowthAnalysis-UniqueGiftsLtd"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "=== Phase 1: Data Sanitation and Preprocessing ===\n",
   "id": "68f04a75b78550f8"
  },
  {
   "cell_type": "markdown",
   "id": "7e304e2f",
   "metadata": {},
   "source": "Download Dataset from Google Drive"
  },
  {
   "cell_type": "code",
   "id": "1a5ef22349c191ab",
   "metadata": {},
   "source": [
    "import requests # for downloading the dataset\n",
    "import os # for file operations\n",
    "from tqdm import tqdm  # progress bar library\n",
    "\n",
    "url = \"https://docs.google.com/spreadsheets/d/1RZ0nYqAUgSivbfIiMsbZfEy2yg5KzNBcbGThzDPHx7c/export?format=csv\"\n",
    "file_path = \"../data/dataset.csv\" # Path to save the dataset\n",
    "\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "total_size = int(response.headers.get('content-length', 0))\n",
    "block_size = 1024  # 1 KB\n",
    "\n",
    "print(\"Downloading dataset with progress:\")\n",
    "\n",
    "with open(file_path, \"wb\") as file, tqdm(\n",
    "    desc=file_path,\n",
    "    total=total_size,\n",
    "    unit='iB',\n",
    "    unit_scale=True,\n",
    "    unit_divisor=1024,\n",
    ") as bar:\n",
    "    for data in response.iter_content(block_size):\n",
    "        file.write(data)\n",
    "        bar.update(len(data))\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(\"Download failed. Please check the URL or your internet connection.\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4a55d76c6590f085",
   "metadata": {},
   "source": "Check if Dataset File Exists"
  },
  {
   "cell_type": "code",
   "id": "1f8cceb0c95953e3",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists(file_path): # Check if the file exists\n",
    "    raise FileNotFoundError(f\"Dataset file not found at {file_path}. Please check the download process.\")\n",
    "\n",
    "df = pd.read_csv(file_path) # Load the dataset\n",
    "print(f\"Dataset loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a80f562ebc60cfa5",
   "metadata": {},
   "source": "Load Dataset into Pandas DataFrame"
  },
  {
   "cell_type": "code",
   "id": "a71b47e72b42024f",
   "metadata": {},
   "source": [
    "# Display the first few rows of the dataset\n",
    "try:\n",
    "    df = pd.read_csv('../data/dataset.csv')  # Adjust the path as necessary\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'online_retail.csv' was not found in the 'data' folder.\")\n",
    "    print(\"Please make sure you have downloaded the dataset and placed it in the correct folder.\")\n",
    "\n",
    "# Display the first 5 rows to get an idea of the data\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "86bef21c2801927b",
   "metadata": {},
   "source": "Initial Data Audit (.info(), .describe(), Missing Values)"
  },
  {
   "cell_type": "code",
   "id": "ee2ff62b888eab86",
   "metadata": {},
   "source": [
    "print(\"Dataframe Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Get summary statistics for numerical columns\n",
    "print(\"Numerical Describe:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Count missing values in each column\n",
    "print(\"Missing Values Count:\")\n",
    "print(df.isnull().sum())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Identify and Remove Duplicate Rows",
   "id": "648744f36e9c818a"
  },
  {
   "cell_type": "code",
   "id": "689cdfa52490e387",
   "metadata": {},
   "source": [
    "# Print shape before dropping duplicates\n",
    "print(f\"Shape before dropping duplicates: {df.shape}\")\n",
    "\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True) # re df\n",
    "\n",
    "# Print shape after dropping duplicates\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")\n",
    "\n",
    "# Drop rows where Customer ID is missing\n",
    "df.dropna(subset=['Customer ID'], inplace=True)\n",
    "\n",
    "# Print shape after dropping missing Customer ID\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")\n",
    "\n",
    "# Verify that missing Customer IDs are handled\n",
    "print(\"\\nMissing values after handling Customer ID:\")\n",
    "print(df.isnull().sum())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f23f4d45153a98cf",
   "metadata": {},
   "source": "Remove Cancelled Orders and Invalid Quantities"
  },
  {
   "cell_type": "code",
   "id": "eaa304db02690297",
   "metadata": {},
   "source": [
    "# Remove cancelled orders (Invoice starts with 'C')\n",
    "df = df[~df['Invoice'].astype(str).str.startswith('C')]\n",
    "\n",
    "# Ensure quantity is positive\n",
    "df = df[df['Quantity'] > 0]\n",
    "\n",
    "# Remove records where price is 0\n",
    "df = df[df['Price'] > 0]\n",
    "\n",
    "# Check the shape of the dataframe after cleaning\n",
    "print(f\"Shape after cleaning transactions: {df.shape}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dd0f266e744ae834",
   "metadata": {},
   "source": "Filter Non-Product Stock Codes (POST, M, etc.)"
  },
  {
   "cell_type": "code",
   "id": "e2bd9108ce3e5909",
   "metadata": {},
   "source": [
    "# (Assuming 'df' is your dataframe after the initial cleaning)\n",
    "\n",
    "def is_product_code(code):\n",
    "\n",
    "    code_str = str(code)\n",
    "    return any(char.isdigit() for char in code_str)\n",
    "\n",
    "# --- Identify codes that would be removed using this new logic ---\n",
    "all_unique_codes = df['StockCode'].unique()\n",
    "codes_to_be_removed = [code for code in all_unique_codes if not is_product_code(code)]\n",
    "print(f\"Following codes (without any digits) will be removed: {codes_to_be_removed}\")\n",
    "\n",
    "\n",
    "# --- Filtering Step ---\n",
    "print(f\"\\nShape before filtering: {df.shape}\")\n",
    "\n",
    "# Apply the function to the 'StockCode' column and keep only the rows that return True\n",
    "df = df[df['StockCode'].apply(is_product_code)]\n",
    "\n",
    "print(f\"Shape after filtering: {df.shape}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ed8c355e150b7c93",
   "metadata": {},
   "source": "Create TotalPrice Feature (Quantity Ã— Price)"
  },
  {
   "cell_type": "code",
   "id": "101c36781c68ec07",
   "metadata": {},
   "source": [
    "# Create TotalPrice column\n",
    "df['TotalPrice'] = df['Quantity'] * df['Price']\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f3f79fa8ecf722ec",
   "metadata": {},
   "source": "Convert InvoiceDate to Datetime Format"
  },
  {
   "cell_type": "code",
   "id": "29d5384200140e9f",
   "metadata": {},
   "source": [
    "# Convert InvoiceDate to datetime\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "print(type(df['InvoiceDate']))\n",
    "print(df['InvoiceDate'].dtype)\n",
    "\n",
    "# 2. create new columns  - Year, Month, DayOfWeek, HourOfDay\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek     # Monday=0, Sunday=6\n",
    "df['HourOfDay'] = df['InvoiceDate'].dt.hour\n",
    "\n",
    "# 3. view the new columns (first 5 rows)\n",
    "print(df[['InvoiceDate', 'Year', 'Month', 'DayOfWeek', 'HourOfDay']].head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7f40b62edcd01ab",
   "metadata": {},
   "source": "Convert Customer ID to Integer Type"
  },
  {
   "cell_type": "code",
   "id": "b658a6835efb1938",
   "metadata": {},
   "source": [
    "df['Customer ID'] = df['Customer ID'].astype(int)  # Convert Customer ID to integer\n",
    "\n",
    "print(df['Customer ID'].dtype)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1bc96862bc77051c",
   "metadata": {},
   "source": "Convert StockCode to String Type"
  },
  {
   "cell_type": "code",
   "id": "3a35e79cff33cd6e",
   "metadata": {},
   "source": [
    "# Convert StockCode to string\n",
    "df['StockCode'] = df['StockCode'].astype(str)  # Convert StockCode to string\n",
    "print(df['StockCode'].dtype)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4ab5030c8372518",
   "metadata": {},
   "source": "Save Cleaned Dataset to CSV"
  },
  {
   "cell_type": "code",
   "id": "ab175774a180a55",
   "metadata": {},
   "source": "df.to_csv('../data/cleaned-dataset.csv', index=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "=== Phase 2: Exploratory Data Analysis (EDA) ====",
   "id": "7509643289d58ae6"
  },
  {
   "cell_type": "markdown",
   "id": "5530ac14",
   "metadata": {},
   "source": "Set Up Visualization Libraries (Matplotlib, Seaborn)"
  },
  {
   "cell_type": "code",
   "id": "8b6c62d9",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Dataset load (Cleaned dataset)\n",
    "import pandas as pd\n",
    "\n",
    "# Robustly load and standardize the cleaned dataset (handles varying column names and ensures dates are parsed)\n",
    "print(\"Loading cleaned dataset (robust)...\")\n",
    "df = pd.read_csv('../data/cleaned-dataset.csv', low_memory=False)\n",
    "\n",
    "# --- Find and parse invoice date column ---\n",
    "date_col = None\n",
    "for c in df.columns:\n",
    "    if 'invoice' in c.lower() and 'date' in c.lower():\n",
    "        date_col = c\n",
    "        break\n",
    "if not date_col:\n",
    "    # fallback common name\n",
    "    if 'InvoiceDate' in df.columns:\n",
    "        date_col = 'InvoiceDate'\n",
    "\n",
    "if not date_col:\n",
    "    raise ValueError(f\"No invoice date column found in cleaned-dataset.csv. Columns: {df.columns.tolist()}\")\n",
    "\n",
    "df[date_col] = pd.to_datetime(df[date_col], errors='coerce', dayfirst=True)\n",
    "df.rename(columns={date_col: 'InvoiceDate'}, inplace=True)\n",
    "\n",
    "# --- Standardize important column names (handles variants from different dataset exports) ---\n",
    "rename_map = {}\n",
    "for c in df.columns:\n",
    "    lc = c.lower().replace(' ', '').replace('_', '')\n",
    "    if lc in ('invoiceno', 'invoice'):\n",
    "        rename_map[c] = 'Invoice'\n",
    "    if lc in ('invoicedate',):\n",
    "        rename_map[c] = 'InvoiceDate'\n",
    "    if lc in ('unitprice', 'price', 'unitpriceinc'):\n",
    "        rename_map[c] = 'Price'\n",
    "    if lc in ('customerid', 'customerid.'):\n",
    "        rename_map[c] = 'Customer ID'\n",
    "    if lc in ('stockcode',):\n",
    "        rename_map[c] = 'StockCode'\n",
    "    if lc in ('quantity',):\n",
    "        rename_map[c] = 'Quantity'\n",
    "    if lc in ('description',):\n",
    "        rename_map[c] = 'Description'\n",
    "    if lc in ('country',):\n",
    "        rename_map[c] = 'Country'\n",
    "\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Verify required columns exist\n",
    "required = ['Invoice', 'InvoiceDate', 'Price', 'Customer ID', 'Quantity']\n",
    "missing = [r for r in required if r not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in cleaned-dataset.csv: {missing}. Available: {df.columns.tolist()}\")\n",
    "\n",
    "# Ensure numeric types\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce').fillna(0).astype(int)\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce').fillna(0.0)\n",
    "\n",
    "# Ensure TotalPrice exists\n",
    "if 'TotalPrice' not in df.columns:\n",
    "    df['TotalPrice'] = df['Quantity'] * df['Price']\n",
    "\n",
    "print(f\"Dataset loaded and standardized. Shape: {df.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5e13918",
   "metadata": {},
   "source": "Monthly Sales Trend Analysis"
  },
  {
   "cell_type": "code",
   "id": "ba7a6c35",
   "metadata": {},
   "source": [
    "# Year-Month column\n",
    "df['YearMonth'] = df['InvoiceDate'].dt.to_period('M')\n",
    "\n",
    "# Group by Year-Month and sum TotalPrice\n",
    "monthly_sales = df.groupby('YearMonth')['TotalPrice'].sum().reset_index()\n",
    "monthly_sales['YearMonth'] = monthly_sales['YearMonth'].astype(str)  # Convert YearMonth to string for plotting\n",
    "\n",
    "# Line chart Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='YearMonth', y='TotalPrice', data=monthly_sales, marker=\"o\")\n",
    "plt.title(\"Monthly Sales Trend\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Sales Revenue (Â£)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "52ec87da",
   "metadata": {},
   "source": "Extract Year and Month from InvoiceDate"
  },
  {
   "cell_type": "code",
   "id": "718c895f",
   "metadata": {},
   "source": [
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Extract Year and Month from InvoiceDate\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['MonthName'] = df['InvoiceDate'].dt.strftime('%B')\n",
    "\n",
    "# Group by Year and MonthName to get total sales\n",
    "monthly_sales_yearly = df.groupby(['Year', 'MonthName'])['TotalPrice'].sum().reset_index()\n",
    "\n",
    "# Reorder the months for better visualization\n",
    "month_order = ['January','February','March','April','May','June',\n",
    "               'July','August','September','October','November','December']\n",
    "monthly_sales_yearly['MonthName'] = pd.Categorical(monthly_sales_yearly['MonthName'], \n",
    "                                                   categories=month_order, \n",
    "                                                   ordered=True)\n",
    "monthly_sales_yearly = monthly_sales_yearly.sort_values(['Year', 'MonthName'])\n",
    "\n",
    "# Plotting the monthly sales by year\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(data=monthly_sales_yearly, x='MonthName', y='TotalPrice', hue='Year', marker='o')\n",
    "plt.title(\"Monthly Sales by Year (Check for Feb & Apr Dips)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Sales Revenue (Â£)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# February data\n",
    "feb_sales = monthly_sales_yearly[monthly_sales_yearly['MonthName'] == \"February\"]['TotalPrice']\n",
    "# April data\n",
    "apr_sales = monthly_sales_yearly[monthly_sales_yearly['MonthName'] == \"April\"]['TotalPrice']\n",
    "\n",
    "# Mean & std check\n",
    "feb_mean = feb_sales.mean()\n",
    "apr_mean = apr_sales.mean()\n",
    "overall_mean = monthly_sales_yearly['TotalPrice'].mean()\n",
    "\n",
    "print(f\"February Mean Sales: {feb_mean}\")\n",
    "print(f\"April Mean Sales: {apr_mean}\")\n",
    "print(f\"Overall Mean Sales: {overall_mean}\")\n",
    "\n",
    "# Check pattern: True if all years' Feb sales < overall mean\n",
    "if hasattr(feb_sales, 'empty') and feb_sales.empty:\n",
    "    feb_pattern = False\n",
    "else:\n",
    "    feb_pattern = bool((feb_sales < overall_mean).all())\n",
    "\n",
    "if hasattr(apr_sales, 'empty') and apr_sales.empty:\n",
    "    apr_pattern = False\n",
    "else:\n",
    "    apr_pattern = bool((apr_sales < overall_mean).all())\n",
    "\n",
    "print(f\"February consistent dip? {feb_pattern}\")\n",
    "print(f\"April consistent dip? {apr_pattern}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "25a446f6",
   "metadata": {},
   "source": "Sales by Day of Week and Hour of Day"
  },
  {
   "cell_type": "code",
   "id": "9e00bc6c",
   "metadata": {},
   "source": [
    "df['DayOfWeek'] = df['InvoiceDate'].dt.day_name()\n",
    "df['HourOfDay'] = df['InvoiceDate'].dt.hour\n",
    "\n",
    "# Sales by Day\n",
    "sales_by_day = df.groupby('DayOfWeek')['TotalPrice'].sum().reindex(\n",
    "    [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    ")\n",
    "\n",
    "# Bar chart â€“ Day\n",
    "sales_by_day.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Sales by Day of Week\")\n",
    "plt.ylabel(\"Total Sales Revenue (Â£)\")\n",
    "plt.show()\n",
    "\n",
    "# Sales by Hour\n",
    "sales_by_hour = df.groupby('HourOfDay')['TotalPrice'].sum()\n",
    "sales_by_hour.plot(kind='bar', color='lightgreen')\n",
    "plt.title(\"Sales by Hour of Day\")\n",
    "plt.ylabel(\"Total Sales Revenue (Â£)\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "52ce18b4",
   "metadata": {},
   "source": "Top 10 Countries by Total Revenue"
  },
  {
   "cell_type": "code",
   "id": "2ba779cd",
   "metadata": {},
   "source": [
    "country_sales = df.groupby('Country')['TotalPrice'].sum().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Top 10\n",
    "top_10_countries = country_sales.head(10)\n",
    "\n",
    "# Plot\n",
    "sns.barplot(x='TotalPrice', y='Country', data=top_10_countries, palette=\"viridis\")\n",
    "plt.title(\"Top 10 Countries by Sales Revenue\")\n",
    "plt.xlabel(\"Total Sales Revenue (Â£)\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4edfb74d",
   "metadata": {},
   "source": "UK vs Rest of World Revenue Share"
  },
  {
   "cell_type": "code",
   "id": "9b3cd935",
   "metadata": {},
   "source": [
    "uk_revenue = df[df['Country'] == 'United Kingdom']['TotalPrice'].sum()\n",
    "total_revenue = df['TotalPrice'].sum()\n",
    "uk_percentage = (uk_revenue / total_revenue) * 100\n",
    "print(f\"UK Revenue %: {uk_percentage:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Revenue Contribution by Country (Chart)",
   "id": "f5636b2f27187c3f"
  },
  {
   "cell_type": "code",
   "id": "bba3840ca8fbcc9d",
   "metadata": {},
   "source": [
    "# Calculate revenue by country\n",
    "country_revenue = df.groupby('Country')['TotalPrice'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Calculate percentages\n",
    "country_percentages = (country_revenue / total_revenue) * 100\n",
    "\n",
    "# For better visualization, group smaller countries (< 1%) into \"Others\"\n",
    "threshold = 1.0\n",
    "major_countries = country_percentages[country_percentages >= threshold]\n",
    "minor_countries_sum = country_percentages[country_percentages < threshold].sum()\n",
    "\n",
    "# Create data for pie chart\n",
    "if minor_countries_sum > 0:\n",
    "    pie_data = major_countries.copy()\n",
    "    pie_data['Others'] = minor_countries_sum\n",
    "else:\n",
    "    pie_data = major_countries\n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.Set3(range(len(pie_data)))\n",
    "wedges, texts, autotexts = plt.pie(pie_data.values,\n",
    "                                   labels=pie_data.index,\n",
    "                                   autopct='%1.1f%%',\n",
    "                                   colors=colors,\n",
    "                                   startangle=90)\n",
    "\n",
    "plt.title('Revenue Distribution by Country', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Improve text readability\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed breakdown\n",
    "print(\"\\nRevenue Breakdown by Country:\")\n",
    "print(\"-\" * 40)\n",
    "for country, percentage in country_percentages.head(10).items():\n",
    "    revenue = country_revenue[country]\n",
    "    print(f\"{country}: Â£{revenue:,.2f} ({percentage:.2f}%)\")\n",
    "\n",
    "if minor_countries_sum > 0:\n",
    "    print(f\"\\nOthers (countries < 1%): Â£{country_revenue[country_percentages < threshold].sum():,.2f} ({minor_countries_sum:.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2bac66c2efe8836e",
   "metadata": {},
   "source": "Revenue by Day of Week (Bar Chart)"
  },
  {
   "cell_type": "code",
   "id": "f458c50229b312ba",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Revenue by DayOfWeek\n",
    "day_sales = df.groupby('DayOfWeek')['TotalPrice'].sum()\n",
    "day_sales.plot(kind='bar', figsize=(7,4), title=\"Revenue by Day of Week\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.show()\n",
    "\n",
    "# Revenue by HourOfDay\n",
    "hour_sales = df.groupby('HourOfDay')['TotalPrice'].sum()\n",
    "hour_sales.plot(kind='bar', figsize=(7,4), title=\"Revenue by Hour of Day\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ed0d1048",
   "metadata": {},
   "source": "Top 10 Products by Quantity and Revenue"
  },
  {
   "cell_type": "code",
   "id": "e8abcc0f",
   "metadata": {},
   "source": [
    "# Top 10 by Quantity Sold\n",
    "top_quantity = df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Top 10 by Revenue\n",
    "top_revenue = df.groupby('Description')['TotalPrice'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"Top 10 by Quantity Sold:\\n\", top_quantity)\n",
    "print(\"\\nTop 10 by Revenue:\\n\", top_revenue)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualize Top Products: Quantity vs Revenue",
   "id": "924e2dfbb4bb2e63"
  },
  {
   "cell_type": "code",
   "id": "53e8799dcfc28464",
   "metadata": {},
   "source": [
    "# Create subplots for both charts\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Top 10 by Quantity - Bar Chart\n",
    "top_quantity.plot(kind='barh', ax=ax1, color='skyblue')\n",
    "ax1.set_title('Top 10 Products by Quantity Sold', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Total Quantity Sold')\n",
    "ax1.set_ylabel('Product Description')\n",
    "\n",
    "# Top 10 by Revenue - Bar Chart  \n",
    "top_revenue.plot(kind='barh', ax=ax2, color='lightgreen')\n",
    "ax2.set_title('Top 10 Products by Revenue', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Total Revenue (Â£)')\n",
    "ax2.set_ylabel('Product Description')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nTop quantity product: {top_quantity.index[0]} ({top_quantity.iloc[0]:,} units)\")\n",
    "print(f\"Top revenue product: {top_revenue.index[0]} (Â£{top_revenue.iloc[0]:,.2f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fff646cf",
   "metadata": {},
   "source": "=== Phase 3: Advanced Analytics â€“ RFM Segmentation ==="
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prepare Data for RFM Analysis, Scoring, and Wholesaler Classification",
   "id": "c9df114d4407b2d"
  },
  {
   "cell_type": "code",
   "id": "5cc8b6b33f405fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:17:01.580883Z",
     "start_time": "2025-08-30T11:17:01.278328Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use the already-loaded `df` (from earlier EDA). If not present, load robustly.\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    df = pd.read_csv('../data/cleaned-dataset.csv', low_memory=False)\n",
    "\n",
    "# Ensure InvoiceDate is datetime\n",
    "if df['InvoiceDate'].dtype == object or not np.issubdtype(df['InvoiceDate'].dtype, np.datetime64):\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Ensure TotalPrice exists\n",
    "if 'TotalPrice' not in df.columns:\n",
    "    df['TotalPrice'] = pd.to_numeric(df['Quantity'], errors='coerce').fillna(0) * pd.to_numeric(df['Price'], errors='coerce').fillna(0.0)\n",
    "\n",
    "# Snapshot date = 1 day after last InvoiceDate\n",
    "snapshot_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
    "print(f\"Snapshot date: {snapshot_date}\")\n",
    "\n",
    "# Recency\n",
    "recency_df = df.groupby('Customer ID').agg(Recency=('InvoiceDate', lambda x: (snapshot_date - x.max()).days)).reset_index()\n",
    "\n",
    "# Frequency (number of unique invoices)\n",
    "frequency_df = df.groupby('Customer ID').agg(Frequency=('Invoice', 'nunique')).reset_index()\n",
    "\n",
    "# Monetary (total spent)\n",
    "monetary_df = df.groupby('Customer ID').agg(Monetary=('TotalPrice', 'sum')).reset_index()\n",
    "\n",
    "# Merge\n",
    "rfm_df = recency_df.merge(frequency_df, on='Customer ID').merge(monetary_df, on='Customer ID')\n",
    "\n",
    "# Add average order value and average order quantity to help classify wholesalers\n",
    "# avg_order_value = Monetary / Frequency\n",
    "rfm_df['AvgOrderValue'] = rfm_df['Monetary'] / rfm_df['Frequency']\n",
    "\n",
    "# average quantity per invoice per customer\n",
    "invoice_qty = df.groupby(['Customer ID', 'Invoice']).agg(InvoiceQty=('Quantity', 'sum')).reset_index()\n",
    "avg_qty = invoice_qty.groupby('Customer ID').agg(AvgOrderQty=('InvoiceQty', 'mean')).reset_index()\n",
    "rfm_df = rfm_df.merge(avg_qty, on='Customer ID', how='left')\n",
    "\n",
    "# RFM scoring using quintiles. Use rank for frequency to reduce qcut issues on identical values.\n",
    "# Handle small number of customers by using qcut with duplicates dropped when necessary.\n",
    "r_labels = [5,4,3,2,1]\n",
    "f_labels = [1,2,3,4,5]\n",
    "m_labels = [1,2,3,4,5]\n",
    "\n",
    "try:\n",
    "    rfm_df['R_Score'] = pd.qcut(rfm_df['Recency'], 5, labels=r_labels)\n",
    "    rfm_df['F_Score'] = pd.qcut(rfm_df['Frequency'].rank(method='first'), 5, labels=f_labels)\n",
    "    rfm_df['M_Score'] = pd.qcut(rfm_df['Monetary'], 5, labels=m_labels)\n",
    "except ValueError:\n",
    "    # fallback when there are too few unique values\n",
    "    rfm_df['R_Score'] = pd.cut(rfm_df['Recency'], bins=5, labels=r_labels)\n",
    "    rfm_df['F_Score'] = pd.cut(rfm_df['Frequency'].rank(method='first'), bins=5, labels=f_labels)\n",
    "    rfm_df['M_Score'] = pd.cut(rfm_df['Monetary'], bins=5, labels=m_labels)\n",
    "\n",
    "# Convert to int (coerce if NaN)\n",
    "rfm_df['R_Score'] = pd.to_numeric(rfm_df['R_Score'], errors='coerce').fillna(1).astype(int)\n",
    "rfm_df['F_Score'] = pd.to_numeric(rfm_df['F_Score'], errors='coerce').fillna(1).astype(int)\n",
    "rfm_df['M_Score'] = pd.to_numeric(rfm_df['M_Score'], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "# RFM segment code and description\n",
    "rfm_df['RFM_Segment'] = rfm_df['R_Score'].astype(str) + rfm_df['F_Score'].astype(str) + rfm_df['M_Score'].astype(str)\n",
    "\n",
    "def map_rfm_segment(row):\n",
    "    r, f, m = row['R_Score'], row['F_Score'], row['M_Score']\n",
    "    if r >= 4 and f >= 4 and m >= 4:\n",
    "        return 'Champions'\n",
    "    if f >= 4 and r >= 3:\n",
    "        return 'Loyal Customers'\n",
    "    if r >= 4 and f <= 2:\n",
    "        return 'Recent Low-Frequency'\n",
    "    if r <= 2 and f <= 2:\n",
    "        return 'Hibernating'\n",
    "    if r <= 2 and f >= 3:\n",
    "        return 'At-Risk Customers'\n",
    "    return 'Potential Loyalists'\n",
    "\n",
    "rfm_df['RFM_Description'] = rfm_df.apply(map_rfm_segment, axis=1)\n",
    "\n",
    "# Classify Wholesaler vs Retail based on simple heuristics\n",
    "# Thresholds can be tuned; these are initial suggestions per project spec\n",
    "wholesale_qty_threshold = 20  # avg qty per order\n",
    "wholesale_value_threshold = 200.0  # avg order value\n",
    "\n",
    "rfm_df['CustomerType'] = np.where((rfm_df['AvgOrderQty'] > wholesale_qty_threshold) | (rfm_df['AvgOrderValue'] > wholesale_value_threshold), 'Wholesaler', 'Retail')\n",
    "\n",
    "# Summary comparisons\n",
    "summary = rfm_df.groupby('CustomerType').agg(\n",
    "    Customers=('Customer ID', 'nunique'),\n",
    "    AvgFrequency=('Frequency', 'mean'),\n",
    "    AvgMonetary=('Monetary', 'mean'),\n",
    "    AvgOrderQty=('AvgOrderQty', 'mean'),\n",
    "    AvgOrderValue=('AvgOrderValue', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print('\\nCustomer type summary:')\n",
    "print(summary)\n",
    "\n",
    "# Save RFM segments\n",
    "rfm_df.to_csv('../data/rfm_segments.csv', index=False)\n",
    "print('\\nSaved RFM segments to ../data/rfm_segments.csv')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot date: 2011-12-11 17:19:00\n",
      "\n",
      "Customer type summary:\n",
      "  CustomerType  Customers  AvgFrequency  AvgMonetary  AvgOrderQty  \\\n",
      "0       Retail        125      2.720000   140.627840    11.399038   \n",
      "1   Wholesaler       5728      6.332577  2979.138843   256.747940   \n",
      "\n",
      "   AvgOrderValue  \n",
      "0      61.894360  \n",
      "1     388.211929  \n",
      "\n",
      "Saved RFM segments to ../data/rfm_segments.csv\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "90a3626104965778",
   "metadata": {},
   "source": "Define RFM Scoring and Segment Mapping"
  },
  {
   "cell_type": "code",
   "id": "109cb19b8c205c62",
   "metadata": {},
   "source": [
    "# Define segment mapping\n",
    "def rfm_segment(row):\n",
    "    r, f, m = row['R_Score'], row['F_Score'], row['M_Score']\n",
    "    if r >= 4 and f >= 4 and m >= 4:\n",
    "        return 'Champions'\n",
    "    elif r >= 4 and f >= 4:\n",
    "        return 'Loyal Customers'\n",
    "    elif r >= 4 and f <= 2:\n",
    "        return 'New Customers'\n",
    "    elif r <= 2 and f >= 3:\n",
    "        return 'At-Risk Customers'\n",
    "    else:\n",
    "        return 'Hibernating'\n",
    "\n",
    "rfm_df['Segment'] = rfm_df.apply(rfm_segment, axis=1)\n",
    "rfm_df['Segment'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d91da96e229de160",
   "metadata": {},
   "source": "create and save country_codes_enrichment.csv"
  },
  {
   "cell_type": "code",
   "id": "f467599e9b03d111",
   "metadata": {},
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "countries = df['Country'].dropna().unique().tolist()\n",
    "country_rows = []\n",
    "for country in countries:\n",
    "    try:\n",
    "        resp = requests.get(f'https://restcountries.com/v3.1/name/{country}?fullText=true', timeout=5)\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            if isinstance(data, list) and len(data) > 0:\n",
    "                c = data[0]\n",
    "                iso2 = c.get('cca2')\n",
    "                iso3 = c.get('cca3')\n",
    "                country_rows.append({'Country': country, 'ISO2': iso2, 'ISO3': iso3})\n",
    "        else:\n",
    "            country_rows.append({'Country': country, 'ISO2': None, 'ISO3': None})\n",
    "    except Exception:\n",
    "        country_rows.append({'Country': country, 'ISO2': None, 'ISO3': None})\n",
    "    time.sleep(0.15)\n",
    "\n",
    "country_codes = pd.DataFrame(country_rows)\n",
    "country_codes.to_csv('../data/country_codes_enrichment.csv', index=False)\n",
    "print('\\nSaved country enrichment to ../data/country_codes_enrichment.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "=== Phase 4: Strategic Recommendations ===",
   "id": "ec23a62889e930c0"
  },
  {
   "cell_type": "markdown",
   "id": "bba7dce061a07d59",
   "metadata": {},
   "source": "Customer Monetary Value Distribution (Wholesaler Hypothesis Check)"
  },
  {
   "cell_type": "code",
   "id": "976644be259bb3a4",
   "metadata": {},
   "source": [
    "# Distribution of Monetary value per customer\n",
    "rfm_df['Monetary'].plot(kind='hist', bins=50, figsize=(8,5), title=\"Customer Monetary Distribution\")\n",
    "plt.xlabel(\"Monetary Value\")\n",
    "plt.show()\n",
    "\n",
    "rfm_df['Monetary'].plot(kind='box', figsize=(6,4), title=\"Monetary Value per Customer\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69b08d4b36ed2514",
   "metadata": {},
   "source": "=== Phase 5: Data Enrichment via API Integration ==="
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Fetch Exchange Rates from API (GBP â†’ USD, EUR) ,\n",
    "Apply Exchange Rates to Top 100 Transactions"
   ],
   "id": "1c01bf066ad4d599"
  },
  {
   "cell_type": "code",
   "id": "c42cb6d7f7461def",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "# Use a free API that doesn't require authentication\n",
    "url = \"https://api.fxratesapi.com/latest?base=GBP&currencies=USD,EUR\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    if 'rates' in data:\n",
    "        gbp_to_usd = data['rates']['USD']\n",
    "        gbp_to_eur = data['rates']['EUR']\n",
    "        print(f\"Live rates - GBP to USD: {gbp_to_usd}, GBP to EUR: {gbp_to_eur}\")\n",
    "    else:\n",
    "        # Fallback rates\n",
    "        gbp_to_usd = 1.27\n",
    "        gbp_to_eur = 1.17\n",
    "        print(\"Using fallback rates\")\n",
    "\n",
    "except requests.RequestException as e:\n",
    "    print(f\"API request failed: {e}\")\n",
    "    # Fallback rates\n",
    "    gbp_to_usd = 1.27\n",
    "    gbp_to_eur = 1.17\n",
    "    print(\"Using fallback rates\")\n",
    "\n",
    "# Apply currency conversion\n",
    "df['TotalPrice_USD'] = df['TotalPrice'] * gbp_to_usd\n",
    "df['TotalPrice_EUR'] = df['TotalPrice'] * gbp_to_eur\n",
    "\n",
    "# Display results\n",
    "print(df[['Invoice', 'TotalPrice', 'TotalPrice_USD', 'TotalPrice_EUR']].head(100))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
